import numpy as np

# Function to initialize Q-table
def initialize_q_table():
    return np.zeros((3**9, 9))

# Function to convert state to index
def state_to_index(state):
    index = 0
    for i in range(9):
        index += (3**i) * state[i]
    return index

# Function to choose action based on epsilon-greedy strategy
def choose_action(state, q_table, epsilon):
    if np.random.rand() < epsilon:
        available_actions = [i for i in range(9) if state[i] == 0]
        return np.random.choice(available_actions)
    else:
        index = state_to_index(state)
        return np.argmax(q_table[index])

# Function to update Q-table based on TD(0) learning
def update_q_table(q_table, state, action, reward, next_state, alpha, gamma):
    state_index = state_to_index(state)
    next_state_index = state_to_index(next_state)
    q_table[state_index, action] += alpha * (reward + gamma * np.max(q_table[next_state_index]) - q_table[state_index, action])

# Function to check if a player wins
def check_win(board, player):
    # Check rows, columns, and diagonals
    for i in range(3):
        if all(board[i][j] == player for j in range(3)) or all(board[j][i] == player for j in range(3)):
            return True
    if all(board[i][i] == player for i in range(3)) or all(board[i][2 - i] == player for i in range(3)):
        return True
    return False

# Function to check if the game is over
def game_over(board):
    return check_win(board, 1) or check_win(board, 2) or not any(0 in row for row in board)

# Function to play a game of Tic-Tac-Toe
def play_game(q_table, epsilon, alpha, gamma):
    # Initialize the board
    board = np.zeros((3, 3), dtype=int)
    state = [0] * 9
    player = 1

    while not game_over(board):
        # Player's turn
        action = choose_action(state, q_table, epsilon)
        row = action // 3
        col = action % 3
        if board[row][col] == 0:
            board[row][col] = player
            state[action] = player

            if check_win(board, player):
                reward = 1
            else:
                reward = 0

            if game_over(board):
                update_q_table(q_table, state, action, reward, state, alpha, gamma)
                break

            # Switch player
            player = 3 - player

            # Opponent's turn
            available_actions = [i for i in range(9) if state[i] == 0]
            opponent_action = np.random.choice(available_actions)
            row = opponent_action // 3
            col = opponent_action % 3
            board[row][col] = player
            state[opponent_action] = player

            if check_win(board, player):
                reward = -1
            else:
                reward = 0

            update_q_table(q_table, state, action, reward, state, alpha, gamma)
            player = 3 - player

    return check_win(board, 1)

# Main function
def main():
    num_episodes = 100
    epsilon = 0.1
    alpha = 0.1
    gamma = 0.9

    q_table = initialize_q_table()

    wins = 0
    for episode in range(num_episodes):
        if play_game(q_table, epsilon, alpha, gamma):
            wins += 1

    print("Winning rate: {:.2f}%".format(wins / num_episodes * 100))

if __name__ == "__main__":
    main()
