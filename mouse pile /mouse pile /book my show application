import tensorflow as tf
import numpy as np

class DuelingQNetwork(tf.keras.Model):
    def __init__(self, state_size, action_size):
        super(DuelingQNetwork, self).__init__()
        self.dense1 = tf.keras.layers.Dense(64, activation='relu')
        self.dense2_advantage = tf.keras.layers.Dense(64, activation='relu')
        self.dense2_value = tf.keras.layers.Dense(64, activation='relu')
        self.dense3_advantage = tf.keras.layers.Dense(action_size, activation='linear')
        self.dense3_value = tf.keras.layers.Dense(1, activation='linear')

    def call(self, state):
        x = self.dense1(state)
        adv = self.dense2_advantage(x)
        val = self.dense2_value(x)
        adv = self.dense3_advantage(adv)
        val = self.dense3_value(val)
        # Combining value and advantage streams to get Q-values
        q_values = val + (adv - tf.reduce_mean(adv, axis=1, keepdims=True))
        return q_values

# Example usage:
state_size = 10
action_size = 5
model = DuelingQNetwork(state_size, action_size)
dummy_state = np.random.random((1, state_size)).astype(np.float32)
q_values = model(dummy_state)
print("Q-values:", q_values)
